{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-2. Transfer Learning\n",
    "- 특정 task를 학습한 모델을 다른 task에 재사용하는 기법\n",
    "- 백지 상태보다 모델의 학습 속도가 빨라짐.\n",
    "- upstream task를 먼저 하고, downstream task를 하는 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upstream Task\n",
    "\n",
    "- 먼저 해결해야 하는 task\n",
    "- 대규모 말뭉치의 문맥을 이해하는 과제\n",
    "    - 다음 단어 맞추기, 빈칸 채우기 등\n",
    "- upstream task 진행과정을 **프리트레인**이라고 부름.\n",
    "\n",
    "글만 있으면 다량의 학습 데이터를 싼값에 만들수 있다.\n",
    "\n",
    "이처럼 데이터 내에서 정답을 만들고, 학습하는 과정을 **자기지도 학습(self-supervised learning)** \n",
    "이라고 한다.\n",
    "\n",
    "### 다음 단어 맞히기 “언어 모델”\n",
    "\n",
    "- 다음 단어 맞히기: 특정 단어 다음에 올 단어를 맞추는 것.\n",
    "    - “티클 모아 ___” 을 맞춰 보시오.\n",
    "- 이를 통해 업스트립 태스크를 수행한 모델을 **언어 모델**이라고 함.\n",
    "\n",
    "### 빈칸 채우기와 “마스크 언어 모델”\n",
    "\n",
    "- 빈칸 채우기 : 문장 가운데 빈 칸이 있고, 가장 적합한 단어를 맟추는 것\n",
    "    - “오는 말이 _____야, 가는 말도 곱다.”\n",
    "- 이를 통해 업스트립 태스크를 수행한 모델을 **마스크 언어 모델**이라고 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downstream Task\n",
    "\n",
    "- 나중에 진행하는 task\n",
    "- 자연어 처리의 구체적인 문제들\n",
    "- 문서 분류, 개체명 인식 등\n",
    "\n",
    "### 종류\n",
    "\n",
    "1. 파인튜닝 : 다운스트림된 task data 전체를 사용. 모델 전체를 Update\n",
    "2. 프롬프트 퓨닝 : 다운스트림된 task data 전체를 사용. 모델 일부를 Update\n",
    "3. 인컨텍스트 러닝 : 다운스트림된 task data 일부를 사용. 모델 Update 안함.\n",
    "    1. 제로샷 러닝 : 모델이 바로 다운스트림 task 수행\n",
    "    2. 원샷 러닝 : 다운스트림된 task data 1건만 참고 후 다운스트림 task 구현\n",
    "    3. 퓨샷 러닝 : 다운스트림된 task data 일부만 참고 후 다운스트림 task 구현"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
